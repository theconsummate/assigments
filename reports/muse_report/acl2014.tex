%
% File acl2014.tex
%
% Contact: koller@ling.uni-potsdam.de, yusuke@nii.ac.jp
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{MUSE: Multilingual Unsupervised or Supervised word Embeddings}

\author{First Author \\
  Affiliation / Address line 1 \\
  {\tt email@domain}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
This report describes the experiments performed on the technique described in \cite{conneau2017word}. Although the goal was to find improvements, none of the designed experiment was able to increase accuracy by a substantial margin. The code was taken from \cite{muserepo} and modified for each experiment.

Remove me: \cite{lample2017unsupervised}

\end{abstract}

\section{Introduction}
\cite{conneau2017word} describes a method to learn a mapping function to align word vectors in one language with another in an unsupervised way. It is assumed that the word vectors for both the source and the target language are already provided. The training process is adversarial with the Mapping function acting as the generator and an additional fully connected feedforward network acting as the Discriminator. The paper uses a linear matrix transformation as the mapping function and therefore, the main hypothesis being tested in this report is that whether other non-linear mapping functions can perform better or not.

\section{Dataset}
Pre-trained vectors English and Spanish were obtained from \url{https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md}. These vectors have been trained on Wikipedia using fastText as described in \cite{bojanowski2016enriching}. The evaluation datasets are as described at \url{https://github.com/facebookresearch/MUSE#get-evaluation-datasets}.

\section{Experiments}
This section describes the various configurations tried out with their respective motivations. There are no experiments involving a change in the Discriminator because there can't be any improvements made in it from a theoretical perspective since it takes a vector as input and outputs a probability indicating whether the vector is original or fake. For this simple setting, a feedforward network is the most optimum system. Obviously, changes could be made in the depth of this network but that is not a very significant design change so I decided to leave it out and focus on experimenting with the mapping and loss functions.

In \cite{conneau2017word}, the mapping function is a matrix. Therefore after the adversarial training, the paper suggests orthogonalization of the matrix followed by (iterative) Procrustes refinement. Since these add-on steps are only possible with a matrix, I removed them from all of the experiments to enable a justified comparison with other non-linear functions which do not go through these post-processing steps.

English was used as the source language while Spanish was the target language. Since the vectors for the source language are being aligned with the target, the monolingual target word embedding scores mostly stay constant. The cross-lingual average only includes the single EN\_ES\_SEMEVAL17 dataset and therefore the values for this score are provided at the end in the summary table. All the experiments use the same hyper-parameters. Training was performed over 5 epochs with 1,000,000 iterations in each epoch.

The code for this report can be viewed at \cite{muserepomine}. This repository is a fork of \cite{muserepo}. The various non-linear functions explored later on have their own corresponding branches.

\begin{table*}[ht]
  \begin{center}
  \begin{tabular}{|c|l|l|l|l|l|l|}
  \hline
  Dataset & Baseline & Baseline-bias & Nonlinear & Piecewise-relu & Piecewise-relu & Wasserstein loss\\
  \hline
  EN\_MTurk-771 & 0.6375 & 0.6596 & 0.4730 & 0.6248 & 0.5905 & 0.5715 \\
  \hline
  EN\_RG-65 & 0.7559 & 0.7890 & 0.5649 & 0.7562 & 0.7569 & 0.7321 \\
  \hline
  EN\_WS-353-REL & 0.6930 & 0.6699 & 0.3294 & 0.6356 & 0.6158 & 0.5913 \\
  \hline
  EN\_YP-130 & 0.4871 & 0.5004 & 0.3174 & 0.4651 & 0.3936 & 0.4988 \\
  \hline
  EN\_MTurk-287 & 0.6717 & 0.6651 & 0.5080 & 0.6518 & 0.6134 & 0.6205 \\
  \hline
  EN\_VERB-143 & 0.3013 & 0.3476 & 0.3602 & 0.2902 & 0.2773 & 0.3932 \\
  \hline
  EN\_SIMLEX-999 & 0.3666 & 0.3748 & 0.2374 & 0.3444 & 0.3304 & 0.3680 \\
  \hline
  EN\_MEN-TR-3k & 0.7439 & 0.7553 & 0.5927 & 0.7246 & 0.7141 & 0.7081 \\
  \hline
  EN\_WS-353-ALL & 0.7327 & 0.7272 & 0.4867 & 0.7004 & 0.6959 & 0.6741 \\
  \hline
  EN\_WS-353-SIM & 0.7601 & 0.7724 & 0.5790 & 0.7496 & 0.7187 & 0.7329 \\
  \hline
  EN\_MC-30 & 0.7985 & 0.8049 & 0.6249 & 0.7936 & 0.7210 & 0.7947 \\
  \hline
  EN\_RW-STANFORD & 0.4945 & 0.5053 & 0.3619 & 0.4793 & 0.4854 & 0.4650 \\
  \hline
  EN\_SEMEVAL17 & 0.7037 & 0.7171 & 0.5886 & 0.6801 & 0.6639 & 0.6614 \\
  \hline
  \end{tabular}
  \end{center}
  \caption{ Monolingual scores for source language (English)}
  \label{monolingual-source}
\end{table*}

\subsection{Baseline} \label{baseline}
The network provided by \cite{muserepo} was considered as the baseline system for future experiments. The mapping function is a matrix and the loss function of the discriminator is binary cross-entropy loss.

\begin{table*}[ht]
  \begin{center}
  \begin{tabular}{|c|l|l|l|l|l|l|}
  \hline
  Dataset & Baseline & Baseline-bias & Nonlinear & Piecewise-relu & Piecewise-relu & Wasserstein loss\\
  \hline
  ES\_SEMEVAL17 & 0.7391 & 0.7392 & 0.7392 & 0.7392 & 0.7392 & 0.7392 \\
  \hline
  ES\_RG-65 & 0.8794 & 0.8794 & 0.8794 & 0.8794 & 0.8794 & 0.8794 \\
  \hline
  ES\_WS-353 & 0.6126 & 0.6126 & 0.6126 & 0.6126 & 0.6126 & 0.6126 \\
  \hline
  ES\_MC-30 & 0.7475 & 0.7475 & 0.7475 & 0.7475 & 0.7475 & 0.7475 \\
  \hline
  \end{tabular}
  \end{center}
  \caption{ Monolingual scores for target language (Spanish)}
  \label{monolingual-target}
\end{table*}

\subsection{Adding a bias}
The mapping function in \ref{baseline} is modified to include a bias variable while the loss function stays the same. The result was a slight marginal improvement but not significant enough to warrant the removal of orthogonalization and Procrustes alignment.

\subsection{Deep Network}
The mapping function used is a deep feedforward network with LeakyReLU as the activation function and consisted of 4 layers. The layers were linear matrix transformations with bias, i.e. $AX + B$. This was the first non-linear function which was tested as this simple network seems like a good intuitive first step. Unfortunately, this function was a complete train wreck as shown by the cross-lingual scores in Table \ref{summary-table} which suggests that no alignment is being learnt. The most likely reason for this output is that the adversarial training process was not able to reach convergence.

\subsection{Piece wise non-linear}
The mapping function used is a piecewise function. These functions are linear everywhere except at the breakpoints. The formula for a piecewise function with $n$ breakpoints is:

$Piecewise(x) = (A_1*x + b_1) + relu(A_n*x + b_n) + ... + relu(A_n*x + b_n)$

A breakpoint means the value of the independent variable at which the function is non-differentiable. At all other values, the function is linear and therefore differentiable. The functions are tested with one and four breakpoints. The scores for the one breakpoint function is only marginally worse than the baseline but the scores keep getting worse by introducing more breakpoints, as can be seen from the scores for the four breakpoints function.

\subsection{Wasserstein Loss}
The mapping function of \ref{baseline} was used but the loss function is changed from binary cross-entropy to Wasserstein loss function. The algorithm described in \cite{arjovsky2017wasserstein} was used to implement it. Although the discriminator is being trained more than the generator, convergence could still not be achieved for this case within 5 epochs, as can be seen by the abysmally low cross-lingual score in Table \ref{summary-table}.

\section{Results}

\begin{table*}[ht]
  \begin{center}
  \begin{tabular}{|c|l|l|l|l|}
  \hline
   & \multicolumn{1}{|p{3cm}|}{Mono-lingual Source word similarity}& \multicolumn{1}{|p{3cm}|}{Mono-lingual Target word similarity} & \multicolumn{1}{|p{3cm}|}{Mono-lingual word similarity} & \multicolumn{1}{|p{3cm}|}{Cross-lingual word similarity} \\
  \hline
  Baseline & 0.62665 & 0.74467 & 0.68566 & 0.68177  \\
  \hline
  Baseline + Bias & 0.63757 & 0.74465 & 0.69111 & 0.70998 \\
  \hline
  Deep Network & 0.46338 & 0.74467 & 0.60402 & 0.01153 \\
  \hline
  Piecewise-one & 0.60735 & 0.74467 & 0.67601 & 0.6660 \\
  \hline
  Piecewise-four & 0.58284 & 0.74467 & 0.66375 & 0.58018 \\
  \hline
  Wasserstein Loss & 0.60090 & 0.74467 & 0.67278 & 0.01945 \\
  \hline
  \end{tabular}
  \end{center}
  \caption{ Comparison of average scores for different experiments with English as source language and Spanish as target language}
  \label{summary-table}
\end{table*}

\subsection{Monolingual source word scores}
This evaluation task measures monolingual word accuracy for the aligned source vectors computed using the mapping functions learned after the training process. The scores are shown in Table \ref{monolingual-source}. The scores are the maximum for Baseline+Bias, which is only slightly higher than the Baseline case. All other systems perform poorly.

\subsection{Monolingual target word scores}
The scores are shown in Table \ref{monolingual-target}. Except the Baseline+Bias case, the scores for all the other systems remain the same. This is because target word vectors go through minimal changes during the alignment process, which is more focussed on aligning the source vectors with target vectors rather than the other way round.

\subsection{Summary of average scores}
Table \ref{summary-table} shows the average scores for each of the different mapping functions along with the cross-lingual scores, which was computed only on the the EN\_ES\_SEMEVAL17 dataset. It is interesting to note that while the monolingual scores don't deteriorate too much, the cross-lingual scores are almost close to zero for the cases, Deep Network and Wasserstein Loss. This suggests that the training could not converge and no learning occurred.

The Piecewise functions were able to converge but the cross lingual scores kept getting lower as the extent of non-linearity was increased, suggesting that it is incredibly difficult to train a non-linear function for this task.

\subsubsection{Linearity of piecewise functions} \label{linearity}
For the Piecewise-one case, a linearity metric was introduced to investigate if the model ended up learning a linear function for majority of the domain. For a function $f(x)$, this metric was calculated as:

$linearity = average(mod(f(a + b) - f(a) - f(b)))$

where $a$ and $b$ are random samples and the average is taken over 10,000 such samples. Lower values mean that $f(x)$ is linear while higher values mean that it is non-linear. The results are shown in Table \ref{linearity-table}.

\begin{table}[h]
  \begin{center}
  \begin{tabular}{|c|l|}
  \hline
   & Linearity \\
  \hline
  Baseline & 0.011146 \\
  \hline
  Piecewise-one & 2.2960 \\
  \hline
  Piecewise-four & 3.0163 \\
  \hline
  \end{tabular}
  \end{center}
  \caption{ Linearity values}
  \label{linearity-table}
\end{table}

It is interesting to note that although Piecewise-one function is significantly non-linear as compared to the baseline, it's monolingual source word scores are only slightly worse. This suggests that there two mapping function is not exactly linear and it should be possible to model a non-linear mapping if the adversarial training can converge.

\section{Conclusion}
This report tested out the hypothesis of learning a non-linear mapping function for aligning word vectors from a source language to another target language through unsupervised learning. To achieve this goal, adversarial learning was used as the training process. A simple linear matrix mapping function was taken as the baseline and the results were compared with a few other non-linear functions. To do an even comparison, all post-processing steps were removed.

The results showed that it is incredibly difficult to achieve convergence for a non-linear mapping function in the training process. Therefore, even though the monolingual scores remained about the same, the cross-lingual scores were essentially zero. It is possible that the training might have converged if the process was continued for a few more epochs but I did not try that out. It is an open question which can be explored in future work.

Another interesting observation which supports the hypothesis is that the piecewise-one function, which is linear at all points except one showed that the cross-lingual scores were not very low as compared to the baseline, even though this function is highly non-linear as suggested by the linearity metric in \ref{linearity}.


% include your own bib file like this:
\bibliographystyle{acl}
\bibliography{acl2014}

\end{document}
